{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREDENTIAL CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "azure_endpoint = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "api_key = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "api_version = os.getenv('API_VERSION')\n",
    "assistant_id = os.getenv('ASSISTANT_ID')\n",
    "model = os.getenv('MODEL')\n",
    "params = {\n",
    "    \"api-version\": api_version\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"api-key\" : api_key\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APIs EXPLORATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. POST /threads API --> CREATE NEW THREAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thread_kGGNSlnotvVPqJk4ILCOBBsH'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def thread_api(azure_endpoint=azure_endpoint, params=params, headers=headers):\n",
    "    thread_api = azure_endpoint + \"openai/threads\"\n",
    "    response = requests.post(thread_api, params=params, headers=headers)\n",
    "    return response.json()['id']\n",
    "\n",
    "thread_id = thread_api()\n",
    "thread_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. POST /messages API --> ADD MESSAGES TO CHAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"NoneType\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequest failed with status code \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43madd_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m, in \u001b[0;36madd_messages\u001b[0;34m(azure_endpoint, thread_id, params, headers, messages)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_messages\u001b[39m(azure_endpoint\u001b[38;5;241m=\u001b[39mazure_endpoint, thread_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, params\u001b[38;5;241m=\u001b[39mparams, headers\u001b[38;5;241m=\u001b[39mheaders, messages : \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhello\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     message_api \u001b[38;5;241m=\u001b[39m \u001b[43mazure_endpoint\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mopenai/threads/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mthread_id\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/messages\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m     body \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages\n\u001b[1;32m      7\u001b[0m         }\n\u001b[1;32m      9\u001b[0m     response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(message_api, \n\u001b[1;32m     10\u001b[0m                                  params\u001b[38;5;241m=\u001b[39mparams, \n\u001b[1;32m     11\u001b[0m                                  headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m     12\u001b[0m                                 json\u001b[38;5;241m=\u001b[39mbody)\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"NoneType\") to str"
     ]
    }
   ],
   "source": [
    "def add_messages(azure_endpoint=azure_endpoint, thread_id=None, params=params, headers=headers, messages : str = 'hello'):\n",
    "    message_api = azure_endpoint + \"openai/threads/\" + thread_id + \"/messages\"\n",
    "\n",
    "    body = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": messages\n",
    "        }\n",
    "    \n",
    "    response = requests.post(message_api, \n",
    "                                 params=params, \n",
    "                                 headers=headers,\n",
    "                                json=body)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Parse the JSON response (assuming the API returns JSON data)\n",
    "        data = response.json()\n",
    "        return data\n",
    "    else:\n",
    "        # If the request failed, print the status code and the response text\n",
    "        print(f\"Request failed with status code {response.status_code}\")\n",
    "        return response.text\n",
    "\n",
    "print(add_messages())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. POST /runs API --> PUSH MESSAGES TO CHATGPT ENGINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'run_QD1q08M8VUWOTGZYnQp34YXP', 'object': 'thread.run', 'created_at': 1723530531, 'assistant_id': 'asst_qccNPjxTUX1AlabUDNxCEbbQ', 'thread_id': 'thread_LGcQrmB7xTWy69fR19WZRrsB', 'status': 'queued', 'started_at': None, 'expires_at': 1723531131, 'cancelled_at': None, 'failed_at': None, 'completed_at': None, 'required_action': None, 'last_error': None, 'model': 'gpt-4o-mini', 'instructions': '### Description: ###\\nThe Buzzebees SKU Matching Agent is designed to streamline the process of matching products from purchase orders or invoice documents with the corresponding products in the Buzzebees database. The primary function of this agent is to handle discrepancies in SKU codes by comparing product names, which are predominantly in Thai, and identifying the most similar matches. The agent utilizes natural language processing techniques to analyze and compare the textual content of product names, providing a structured output in JSON format that includes the matched product, its SKU, and the confidence level of the match.\\n\\n### Workflow: ###\\n1. **Receive Invoice Content:** The agent receives the textual content of invoices or purchase orders, typically processed through OCR (Optical Character Recognition) technology.\\n\\n2. **Extract Product Details:** The agent detects and extracts product details from the provided invoice content, storing this data temporarily for comparison.\\n\\n3. **Receive SKU Data from Buzzebees:** The agent receives and stores product data, including product names and SKUs, from the Buzzebees database.\\n\\n4. **Product Name Similarity Matching:** The agent uses its language processing capabilities to compare the product names from the invoice content against those in the Buzzebees database. It assesses the similarity between names and determines the most likely matches.\\n\\n5. **Generate JSON Output:•• For each product from the invoice, the agent outputs a JSON object containing the matched product name from the Buzzebees database, its corresponding SKU, and a probability score indicating the confidence level of the match.\\n\\n### JSON Output Example: ###\\n\\n{\\n    \"vendor_sku\":\"1601313158\",\\n    \"vendor_product\":\"ไอวี่ นมเปรี้ยวยูเอชทีพลัส ลิ้นจี่ 180\",\\n    \"bzbs_product\":\"ไอวี่โยเกิร์ตพร้อมดื่ม ยูเอชที รสลิ้นจี่ 180มล. แพ็ค4\",\\n    \"bzbs_sku\":\"1-GDS-IVY00-000000005\",\\n    \"probability\":0.47\\n}\\n\\n### Key Capabilities: ###\\n**OCR Content Interpretation:** Understand and process OCR-generated text to accurately extract product details.\\n\\n**Textual Similarity Analysis:** Utilize NLP techniques to compare and match product names, particularly in Thai, despite variations in phrasing or formatting.\\n\\n**Contextual Memory:** Retain information about product details throughout the comparison process to ensure accurate matching.\\n\\n**Confidence Scoring:** Provide a probability score indicating the level of confidence in the matched product, helping to assess the reliability of the match.', 'tools': [], 'tool_resources': {}, 'metadata': {}, 'temperature': 0.9, 'top_p': 1.0, 'max_completion_tokens': None, 'max_prompt_tokens': None, 'truncation_strategy': {'type': 'auto', 'last_messages': None}, 'incomplete_details': None, 'usage': None, 'response_format': 'auto', 'tool_choice': 'auto', 'parallel_tool_calls': True}\n"
     ]
    }
   ],
   "source": [
    "def runs_thread(azure_endpoint=azure_endpoint, thread_id=None, params=params, headers=headers, assistant_id=None, model=model):\n",
    "    run_api = azure_endpoint + \"openai/threads/\" + thread_id + \"/runs\"\n",
    "    body = {\n",
    "        \"assistant_id\": assistant_id,\n",
    "        \"model\": model\n",
    "        }\n",
    "\n",
    "    response = requests.post(run_api,params=params,headers=headers,json=body)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Parse the JSON response (assuming the API returns JSON data)\n",
    "        data = response.json()\n",
    "        return data\n",
    "    else:\n",
    "        # If the request failed, print the status code and the response text\n",
    "        print(f\"Request failed with status code {response.status_code}\")\n",
    "        return response.text\n",
    "\n",
    "print(runs_thread())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. GET /messages API --> REQUEST CHAT HISTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_history(azure_endpoint=azure_endpoint, thread_id=None, params=params, headers=headers):\n",
    "    message_api = azure_endpoint + \"openai/threads/\" + thread_id + \"/messages\"\n",
    "    response = requests.get(message_api, params=params, headers=headers)\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "            # Parse the JSON response (assuming the API returns JSON data)\n",
    "            data = response.json()\n",
    "\n",
    "            # Check if the response came from assistant or not\n",
    "            if (data[\"data\"][0][\"role\"] != 'assistant') or (len(data[\"data\"][0][\"content\"]) == 0) :\n",
    "                time.sleep(1)\n",
    "                get_chat_history()\n",
    "            else:\n",
    "                return data\n",
    "            \n",
    "    else:\n",
    "        # If the request failed, print the status code and the response text\n",
    "        print(f\"Request failed with status code {response.status_code}\")\n",
    "        return response.text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GET ONLY LATEST CHAT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_chat_history()[\"data\"][0][\"content\"][0]['text']['value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXTRACT JSON FROM RESPONSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_gfQQSAw53uX8wgJM8q2HceXL',\n",
       " 'object': 'thread.message',\n",
       " 'created_at': 1723364684,\n",
       " 'assistant_id': 'asst_qccNPjxTUX1AlabUDNxCEbbQ',\n",
       " 'thread_id': 'thread_LGcQrmB7xTWy69fR19WZRrsB',\n",
       " 'run_id': 'run_5M4upouk6W9DXr3cLotXmrl5',\n",
       " 'role': 'assistant',\n",
       " 'content': [{'type': 'text',\n",
       "   'text': {'value': 'Hi again! How can I help you today?',\n",
       "    'annotations': []}}],\n",
       " 'attachments': [],\n",
       " 'metadata': {}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_response = get_chat_history()[\"data\"][6]\n",
    "full_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi again! How can I help you today?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_response['content'][0]['text']['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json(response):\n",
    "    return json.loads(response.split('```')[1].replace('\\n', '').replace('json', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REQUEST MATCHING DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CREATE PROMPT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                Here is the invoice data that is read from vendor invoice:\n",
      "                -- VENDOR DATA STARTS HERE --\n",
      "\n",
      "                vendor_data\n",
      "\n",
      "                -- VENDOR DATA ENDS HERE --\n",
      "\n",
      "                And, here is the product data from Buzzebees database:\n",
      "                -- BUZZEBEES DATA STARTS HERE --\n",
      "\n",
      "                bzbs_data\n",
      "\n",
      "                -- BUZZEBEES DATA ENDS HERE --\n",
      "\n",
      "                Please provide the matching result in JSON format.\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "from prompt import GetPrompt\n",
    "\n",
    "default_prompt = GetPrompt('vendor_data', 'bzbs_data').prompt\n",
    "print(default_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MAIN FUNCTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_match(azure_endpoint=azure_endpoint, thread_id=None,assistant_id=None, vendor_data : str=None, bzbs_data : str=None):\n",
    "\n",
    "    thread_id = thread_api()\n",
    "    \n",
    "    prompt = GetPrompt(vendor_data, bzbs_data).prompt\n",
    "    \n",
    "    add_messages(thread_id=thread_id,messages=prompt)\n",
    "\n",
    "    runs_thread(thread_id=thread_id, assistant_id=assistant_id)\n",
    "\n",
    "    response = get_chat_history()[\"data\"][0][\"content\"][0]['text']['value']\n",
    "\n",
    "    result = extract_json(response)\n",
    "\n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
